{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1099232,"sourceType":"datasetVersion","datasetId":614679}],"dockerImageVersionId":30673,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Medical MNIST Image Classification\n\nHi all, this is an example attempt of classifying the medical mnist dataset, it would be highly recommended to have access to GPU's when computing as this is quite time consuming on a CPU","metadata":{}},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nimport keras\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nfrom skimage import io","metadata":{"execution":{"iopub.status.busy":"2024-03-25T09:03:51.642298Z","iopub.execute_input":"2024-03-25T09:03:51.642654Z","iopub.status.idle":"2024-03-25T09:04:16.385675Z","shell.execute_reply.started":"2024-03-25T09:03:51.642626Z","shell.execute_reply":"2024-03-25T09:04:16.384155Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-03-25 09:03:55.266476: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-25 09:03:55.266619: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-25 09:03:55.434256: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load the dataset\n\nHere we can create a set and assign each folder (key) to an index (value), where we can then create a df appending the category and the index relating to the folder we are interested in.","metadata":{}},{"cell_type":"code","source":"df_lst = []\ncat_set = {}\ndir_location = \"../input/medical-mnist\"\nfor idx, category in enumerate(os.listdir(dir_location)):\n    cat_set[category] = idx\n    for image in os.listdir(\"../input/medical-mnist/\"+category):\n        df_lst.append([category+\"/\"+image, cat_set[category]])\ndf = pd.DataFrame(df_lst)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T09:04:45.950245Z","iopub.execute_input":"2024-03-25T09:04:45.950954Z","iopub.status.idle":"2024-03-25T09:04:50.434362Z","shell.execute_reply.started":"2024-03-25T09:04:45.950919Z","shell.execute_reply":"2024-03-25T09:04:50.433180Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Visualize the df\n\nas we can see we have a pd df which contains close to 60,000 records with 2 columns, where column 1 represents the images name wrt its parent dir, and column 2 represents the labelling of the data","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-25T09:04:53.074748Z","iopub.execute_input":"2024-03-25T09:04:53.075172Z","iopub.status.idle":"2024-03-25T09:04:53.090577Z","shell.execute_reply.started":"2024-03-25T09:04:53.075139Z","shell.execute_reply":"2024-03-25T09:04:53.089603Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                       0  1\n0  AbdomenCT/003646.jpeg  0\n1  AbdomenCT/003998.jpeg  0\n2  AbdomenCT/001273.jpeg  0\n3  AbdomenCT/001609.jpeg  0\n4  AbdomenCT/007646.jpeg  0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AbdomenCT/003646.jpeg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AbdomenCT/003998.jpeg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AbdomenCT/001273.jpeg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AbdomenCT/001609.jpeg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AbdomenCT/007646.jpeg</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Visualising the dataset\n\nHere we simply grab a couple of images from each dataset, by iterating through a pandas df, we can collect 5 images and then simpy join the path of these strings in the df with the main directory, where we can then output the resulting images, just to display what we are viewing","metadata":{}},{"cell_type":"code","source":"abdominal_ct_images = df[df[1] == 0][0][:5]\nbreast_mri_images = df[df[1] == 1][0][:5]\ncxr_images = df[df[1] == 3][0][:5]\nchest_ct_images = df[df[1] == 5][0][:5]\nhand_ct_images = df[df[1] == 2][0][:5]\nhead_ct_images = df[df[1] == 4][0][:5]\n\n\ndfs = [abdominal_ct_images, breast_mri_images, cxr_images, chest_ct_images, hand_ct_images, head_ct_images]\nnames = ['abdominal_ct_images', 'breast_mri_images', 'cxr_images', 'chest_ct_images', 'hand_ct_images', 'head_ct_images']\nfor i, df in enumerate(dfs, start=1):\n    print(names[i - 1])\n    count = 0 \n    for value in df:\n        plt.figure(figsize=(12, 4))\n        image_path = os.path.join(dir_location, value)\n        image = Image.open(image_path)\n        \n        plt.subplot(1, 6, count+1)\n        plt.imshow(image)\n        plt.title(f\"Image {count}\")\n        plt.axis(\"off\")\n        plt.show()\n        count+=1\n","metadata":{"execution":{"iopub.status.busy":"2024-03-25T01:04:18.857738Z","iopub.execute_input":"2024-03-25T01:04:18.858147Z","iopub.status.idle":"2024-03-25T01:04:18.864399Z","shell.execute_reply.started":"2024-03-25T01:04:18.858116Z","shell.execute_reply":"2024-03-25T01:04:18.863372Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"## Setting up our Device and Hyperparameters:","metadata":{}},{"cell_type":"code","source":"device = torch.device('cpu')\n\n#represents the nature of the image, for example coloured images would have an input of 3 as it would be a\n#column vector of rgb, as this is a greyscale it would simply be a density of 0-1\nsize_of_input = 1\n\n#refers to how big our 'step' size is when performing our optimization\nlearning_rate = .01\n\n#as we have close to 60,000 elements, we will want to split the data into batches for our optimization\n#hence we also need to account for the fact that some of these images will be used for testing/validation.\nbatch_size = 50\n\n#the number of iterations we are interested in for each batch, Ie its an external loop before the inner loop of the batches\nepochs = 10\n\n#how many outputs of probabilites are we interested in\nfinal_output_layer = 6","metadata":{"execution":{"iopub.status.busy":"2024-03-25T09:04:58.669808Z","iopub.execute_input":"2024-03-25T09:04:58.671345Z","iopub.status.idle":"2024-03-25T09:04:58.678195Z","shell.execute_reply.started":"2024-03-25T09:04:58.671295Z","shell.execute_reply":"2024-03-25T09:04:58.676506Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Defining our CNN\n\nstarting from a 32x32 image we produce a 5x5 convolution/kernal, with 32 feature maps\nthis means in our first conv2d layer we have 32 feature maps both with size 28x28\nwe then perform max pooling with a 2x2 kernal map with a stride of 2. this leaves us with 32 feature maps with 14x14\n        \nwe then take our 32 feature maps as input and use another 5x5 feature map where we plan to return 16 feature maps\nthis gives us 16 feature maps with 10x10 dimensions each\n\nwe then flatten our output of the cnn so we can use it in the fully connected layers, we also implement a dropout with a 10% chance liklihood that an element can be zeroed out\n        \nwe then create a fully connected layer of size 16*5*5 as we have 16 feature maps of size 5x5 at this point and plan to output 120 nodes, where with some additional fully connected layers we plan to output the probability\n        \n        ","metadata":{}},{"cell_type":"code","source":"class CNN(nn.Module):\n    #mat1 and mat2 shapes cannot be multiplied (50x3136 and 784x64)\n    def __init__(self, in_channels, num_classes):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=32, kernel_size=3)\n        self.pool1 = nn.MaxPool2d(2,2)\n        \n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3)\n        self.pool2 = nn.MaxPool2d(2,2)\n        \n        self.flatten = nn.Flatten()\n        self.dropout = nn.Dropout(0.2)\n        \n        self.lin1 = nn.Linear(64*7*7, 64)\n        #self.lin1 = nn.Linear(16*7*7, 64)\n        self.lin2 = nn.Linear(64, num_classes)\n        \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.pool1(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool2(x)\n        x = self.flatten(x)\n        x = self.dropout(x)\n        x = F.relu(self.lin1(x))\n        x = self.lin2(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2024-03-25T09:14:29.347813Z","iopub.execute_input":"2024-03-25T09:14:29.349208Z","iopub.status.idle":"2024-03-25T09:14:29.361427Z","shell.execute_reply.started":"2024-03-25T09:14:29.349164Z","shell.execute_reply":"2024-03-25T09:14:29.360102Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Create a formal class where we can quickly utilize the information in the df","metadata":{}},{"cell_type":"code","source":"# class Dataset(Dataset):\n    \n#     def __init__(self, df, root_directory, transform=None):\n#         self.annotations = df\n#         self.root_directory = root_directory\n#         self.transform = transform\n        \n#     def __len__(self):\n#         return len(self.annotations)\n    \n#     def __getitem__(self, index):\n#         img_path = os.path.join(self.root_directory, self.annotations.iloc[index, 0])\n#         image = io.imread(img_path)\n#         y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n        \n#         if self.transform:\n#             image = self.transform(image)\n        \n#         return (image, y_label)\n\nclass Dataset_Class(Dataset):\n    def __init__(self, df, root_directory, transform=None):\n        self.annotations = df\n        self.root_directory = root_directory\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.annotations)\n    \n    def __getitem__(self, index):\n        img_path = os.path.join(self.root_directory, self.annotations.iloc[index, 0])\n        image = io.imread(img_path)\n        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return (image, y_label)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T09:14:31.175895Z","iopub.execute_input":"2024-03-25T09:14:31.176310Z","iopub.status.idle":"2024-03-25T09:14:31.187552Z","shell.execute_reply.started":"2024-03-25T09:14:31.176278Z","shell.execute_reply":"2024-03-25T09:14:31.186071Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"new_dataset = Dataset_Class(df=df, root_directory=dir_location,transform=transforms.ToTensor())","metadata":{"execution":{"iopub.status.busy":"2024-03-25T09:14:32.065168Z","iopub.execute_input":"2024-03-25T09:14:32.065686Z","iopub.status.idle":"2024-03-25T09:14:32.074099Z","shell.execute_reply.started":"2024-03-25T09:14:32.065649Z","shell.execute_reply":"2024-03-25T09:14:32.072274Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"len(new_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T09:14:32.546466Z","iopub.execute_input":"2024-03-25T09:14:32.546910Z","iopub.status.idle":"2024-03-25T09:14:32.555325Z","shell.execute_reply.started":"2024-03-25T09:14:32.546879Z","shell.execute_reply":"2024-03-25T09:14:32.553970Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"58954"},"metadata":{}}]},{"cell_type":"markdown","source":"## Creating the partitions of the dataset so it can be 80% training, 20% testing\n\n\nas we can see we are just going to create a generic training and testing datasets, where we have a training size of 80% of the initial dataset and the test data set having the remaining 20%, we note that we will not be using a validation set in this example","metadata":{}},{"cell_type":"code","source":"len_train = len(new_dataset)*.8\nlen_test = len(new_dataset) - len_train\nprint(len_train, len_test)\nprint(len_train + len_test)\nprint(len_train + len_test == len(new_dataset))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-25T09:14:33.666010Z","iopub.execute_input":"2024-03-25T09:14:33.666494Z","iopub.status.idle":"2024-03-25T09:14:33.675813Z","shell.execute_reply.started":"2024-03-25T09:14:33.666461Z","shell.execute_reply":"2024-03-25T09:14:33.674147Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"47163.200000000004 11790.799999999996\n58954.0\nTrue\n","output_type":"stream"}]},{"cell_type":"code","source":"len_train_int = 47163\nlen_test_int = 11791\ntrain_set, test_set = torch.utils.data.random_split(new_dataset,[len_train_int,len_test_int])\n\ntrain_loader = DataLoader(train_set, batch_size=(batch_size), shuffle=True)\ntest_loader = DataLoader(test_set, batch_size=(batch_size), shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T09:14:34.312868Z","iopub.execute_input":"2024-03-25T09:14:34.313392Z","iopub.status.idle":"2024-03-25T09:14:34.329993Z","shell.execute_reply.started":"2024-03-25T09:14:34.313355Z","shell.execute_reply":"2024-03-25T09:14:34.328231Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## Training the model\n\nwe first will initialise the network with the number of input channels, output classes and to the cpu","metadata":{}},{"cell_type":"code","source":"model = CNN(size_of_input, final_output_layer).to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\nfor epoch in range(epochs):\n    for batch, (data, targets) in enumerate(train_loader):\n        data = data.to(device=device)\n        targets = targets.to(device=device)\n\n        #Forward\n        scores = model(data)\n        loss = criterion(scores, targets)\n\n        #Backward\n        optimizer.zero_grad()\n        loss.backward()\n\n        # Gradient descent\n        optimizer.step()\n\n    print(epoch, \"Current Loss:\", loss)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-25T09:14:35.100932Z","iopub.execute_input":"2024-03-25T09:14:35.102640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluating the model","metadata":{}},{"cell_type":"code","source":"def evaluate(loader, model):\n    correct = 0\n    total = 0\n    model.eval()\n    with torch.no_grad():\n        for x,y in loader:\n            x = x.to(device=device)\n            y = y.to(device=device)\n            \n            scores = model(x)\n            _, pred = scores.max(1)\n            correct += (pred == y).sum()\n            total += pred.size(0)\n        print(\"Accuracy:\", correct/total*100, \"%\")\n    \nevaluate(train_loader, model)\nevaluate(test_loader, model)","metadata":{},"execution_count":null,"outputs":[]}]}